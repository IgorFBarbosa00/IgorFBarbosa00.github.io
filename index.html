<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Asciidoctor 2.0.17">
<meta name="author" content="Igor Barbosa">
<title>Processamento Digital de Imagens</title>
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700">
<style>
/*! Asciidoctor default stylesheet | MIT License | https://asciidoctor.org */
/* Uncomment the following line when using as a custom stylesheet */
/* @import "https://fonts.googleapis.com/css?family=Open+Sans:300,300italic,400,400italic,600,600italic%7CNoto+Serif:400,400italic,700,700italic%7CDroid+Sans+Mono:400,700"; */
html{font-family:sans-serif;-webkit-text-size-adjust:100%}
a{background:none}
a:focus{outline:thin dotted}
a:active,a:hover{outline:0}
h1{font-size:2em;margin:.67em 0}
b,strong{font-weight:bold}
abbr{font-size:.9em}
abbr[title]{cursor:help;border-bottom:1px dotted #dddddf;text-decoration:none}
dfn{font-style:italic}
hr{height:0}
mark{background:#ff0;color:#000}
code,kbd,pre,samp{font-family:monospace;font-size:1em}
pre{white-space:pre-wrap}
q{quotes:"\201C" "\201D" "\2018" "\2019"}
small{font-size:80%}
sub,sup{font-size:75%;line-height:0;position:relative;vertical-align:baseline}
sup{top:-.5em}
sub{bottom:-.25em}
img{border:0}
svg:not(:root){overflow:hidden}
figure{margin:0}
audio,video{display:inline-block}
audio:not([controls]){display:none;height:0}
fieldset{border:1px solid silver;margin:0 2px;padding:.35em .625em .75em}
legend{border:0;padding:0}
button,input,select,textarea{font-family:inherit;font-size:100%;margin:0}
button,input{line-height:normal}
button,select{text-transform:none}
button,html input[type=button],input[type=reset],input[type=submit]{-webkit-appearance:button;cursor:pointer}
button[disabled],html input[disabled]{cursor:default}
input[type=checkbox],input[type=radio]{padding:0}
button::-moz-focus-inner,input::-moz-focus-inner{border:0;padding:0}
textarea{overflow:auto;vertical-align:top}
table{border-collapse:collapse;border-spacing:0}
*,::before,::after{box-sizing:border-box}
html,body{font-size:100%}
body{background:#fff;color:rgba(0,0,0,.8);padding:0;margin:0;font-family:"Noto Serif","DejaVu Serif",serif;line-height:1;position:relative;cursor:auto;-moz-tab-size:4;-o-tab-size:4;tab-size:4;word-wrap:anywhere;-moz-osx-font-smoothing:grayscale;-webkit-font-smoothing:antialiased}
a:hover{cursor:pointer}
img,object,embed{max-width:100%;height:auto}
object,embed{height:100%}
img{-ms-interpolation-mode:bicubic}
.left{float:left!important}
.right{float:right!important}
.text-left{text-align:left!important}
.text-right{text-align:right!important}
.text-center{text-align:center!important}
.text-justify{text-align:justify!important}
.hide{display:none}
img,object,svg{display:inline-block;vertical-align:middle}
textarea{height:auto;min-height:50px}
select{width:100%}
.subheader,.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{line-height:1.45;color:#7a2518;font-weight:400;margin-top:0;margin-bottom:.25em}
div,dl,dt,dd,ul,ol,li,h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6,pre,form,p,blockquote,th,td{margin:0;padding:0}
a{color:#2156a5;text-decoration:underline;line-height:inherit}
a:hover,a:focus{color:#1d4b8f}
a img{border:0}
p{line-height:1.6;margin-bottom:1.25em;text-rendering:optimizeLegibility}
p aside{font-size:.875em;line-height:1.35;font-style:italic}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{font-family:"Open Sans","DejaVu Sans",sans-serif;font-weight:300;font-style:normal;color:#ba3925;text-rendering:optimizeLegibility;margin-top:1em;margin-bottom:.5em;line-height:1.0125em}
h1 small,h2 small,h3 small,#toctitle small,.sidebarblock>.content>.title small,h4 small,h5 small,h6 small{font-size:60%;color:#e99b8f;line-height:0}
h1{font-size:2.125em}
h2{font-size:1.6875em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.375em}
h4,h5{font-size:1.125em}
h6{font-size:1em}
hr{border:solid #dddddf;border-width:1px 0 0;clear:both;margin:1.25em 0 1.1875em}
em,i{font-style:italic;line-height:inherit}
strong,b{font-weight:bold;line-height:inherit}
small{font-size:60%;line-height:inherit}
code{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;font-weight:400;color:rgba(0,0,0,.9)}
ul,ol,dl{line-height:1.6;margin-bottom:1.25em;list-style-position:outside;font-family:inherit}
ul,ol{margin-left:1.5em}
ul li ul,ul li ol{margin-left:1.25em;margin-bottom:0}
ul.square li ul,ul.circle li ul,ul.disc li ul{list-style:inherit}
ul.square{list-style-type:square}
ul.circle{list-style-type:circle}
ul.disc{list-style-type:disc}
ol li ul,ol li ol{margin-left:1.25em;margin-bottom:0}
dl dt{margin-bottom:.3125em;font-weight:bold}
dl dd{margin-bottom:1.25em}
blockquote{margin:0 0 1.25em;padding:.5625em 1.25em 0 1.1875em;border-left:1px solid #ddd}
blockquote,blockquote p{line-height:1.6;color:rgba(0,0,0,.85)}
@media screen and (min-width:768px){h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2}
h1{font-size:2.75em}
h2{font-size:2.3125em}
h3,#toctitle,.sidebarblock>.content>.title{font-size:1.6875em}
h4{font-size:1.4375em}}
table{background:#fff;margin-bottom:1.25em;border:1px solid #dedede;word-wrap:normal}
table thead,table tfoot{background:#f7f8f7}
table thead tr th,table thead tr td,table tfoot tr th,table tfoot tr td{padding:.5em .625em .625em;font-size:inherit;color:rgba(0,0,0,.8);text-align:left}
table tr th,table tr td{padding:.5625em .625em;font-size:inherit;color:rgba(0,0,0,.8)}
table tr.even,table tr.alt{background:#f8f8f7}
table thead tr th,table tfoot tr th,table tbody tr td,table tr td,table tfoot tr td{line-height:1.6}
h1,h2,h3,#toctitle,.sidebarblock>.content>.title,h4,h5,h6{line-height:1.2;word-spacing:-.05em}
h1 strong,h2 strong,h3 strong,#toctitle strong,.sidebarblock>.content>.title strong,h4 strong,h5 strong,h6 strong{font-weight:400}
.center{margin-left:auto;margin-right:auto}
.stretch{width:100%}
.clearfix::before,.clearfix::after,.float-group::before,.float-group::after{content:" ";display:table}
.clearfix::after,.float-group::after{clear:both}
:not(pre).nobreak{word-wrap:normal}
:not(pre).nowrap{white-space:nowrap}
:not(pre).pre-wrap{white-space:pre-wrap}
:not(pre):not([class^=L])>code{font-size:.9375em;font-style:normal!important;letter-spacing:0;padding:.1em .5ex;word-spacing:-.15em;background:#f7f7f8;border-radius:4px;line-height:1.45;text-rendering:optimizeSpeed}
pre{color:rgba(0,0,0,.9);font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;line-height:1.45;text-rendering:optimizeSpeed}
pre code,pre pre{color:inherit;font-size:inherit;line-height:inherit}
pre>code{display:block}
pre.nowrap,pre.nowrap pre{white-space:pre;word-wrap:normal}
em em{font-style:normal}
strong strong{font-weight:400}
.keyseq{color:rgba(51,51,51,.8)}
kbd{font-family:"Droid Sans Mono","DejaVu Sans Mono",monospace;display:inline-block;color:rgba(0,0,0,.8);font-size:.65em;line-height:1.45;background:#f7f7f7;border:1px solid #ccc;border-radius:3px;box-shadow:0 1px 0 rgba(0,0,0,.2),inset 0 0 0 .1em #fff;margin:0 .15em;padding:.2em .5em;vertical-align:middle;position:relative;top:-.1em;white-space:nowrap}
.keyseq kbd:first-child{margin-left:0}
.keyseq kbd:last-child{margin-right:0}
.menuseq,.menuref{color:#000}
.menuseq b:not(.caret),.menuref{font-weight:inherit}
.menuseq{word-spacing:-.02em}
.menuseq b.caret{font-size:1.25em;line-height:.8}
.menuseq i.caret{font-weight:bold;text-align:center;width:.45em}
b.button::before,b.button::after{position:relative;top:-1px;font-weight:400}
b.button::before{content:"[";padding:0 3px 0 2px}
b.button::after{content:"]";padding:0 2px 0 3px}
p a>code:hover{color:rgba(0,0,0,.9)}
#header,#content,#footnotes,#footer{width:100%;margin:0 auto;max-width:62.5em;*zoom:1;position:relative;padding-left:.9375em;padding-right:.9375em}
#header::before,#header::after,#content::before,#content::after,#footnotes::before,#footnotes::after,#footer::before,#footer::after{content:" ";display:table}
#header::after,#content::after,#footnotes::after,#footer::after{clear:both}
#content{margin-top:1.25em}
#content::before{content:none}
#header>h1:first-child{color:rgba(0,0,0,.85);margin-top:2.25rem;margin-bottom:0}
#header>h1:first-child+#toc{margin-top:8px;border-top:1px solid #dddddf}
#header>h1:only-child,body.toc2 #header>h1:nth-last-child(2){border-bottom:1px solid #dddddf;padding-bottom:8px}
#header .details{border-bottom:1px solid #dddddf;line-height:1.45;padding-top:.25em;padding-bottom:.25em;padding-left:.25em;color:rgba(0,0,0,.6);display:flex;flex-flow:row wrap}
#header .details span:first-child{margin-left:-.125em}
#header .details span.email a{color:rgba(0,0,0,.85)}
#header .details br{display:none}
#header .details br+span::before{content:"\00a0\2013\00a0"}
#header .details br+span.author::before{content:"\00a0\22c5\00a0";color:rgba(0,0,0,.85)}
#header .details br+span#revremark::before{content:"\00a0|\00a0"}
#header #revnumber{text-transform:capitalize}
#header #revnumber::after{content:"\00a0"}
#content>h1:first-child:not([class]){color:rgba(0,0,0,.85);border-bottom:1px solid #dddddf;padding-bottom:8px;margin-top:0;padding-top:1rem;margin-bottom:1.25rem}
#toc{border-bottom:1px solid #e7e7e9;padding-bottom:.5em}
#toc>ul{margin-left:.125em}
#toc ul.sectlevel0>li>a{font-style:italic}
#toc ul.sectlevel0 ul.sectlevel1{margin:.5em 0}
#toc ul{font-family:"Open Sans","DejaVu Sans",sans-serif;list-style-type:none}
#toc li{line-height:1.3334;margin-top:.3334em}
#toc a{text-decoration:none}
#toc a:active{text-decoration:underline}
#toctitle{color:#7a2518;font-size:1.2em}
@media screen and (min-width:768px){#toctitle{font-size:1.375em}
body.toc2{padding-left:15em;padding-right:0}
#toc.toc2{margin-top:0!important;background:#f8f8f7;position:fixed;width:15em;left:0;top:0;border-right:1px solid #e7e7e9;border-top-width:0!important;border-bottom-width:0!important;z-index:1000;padding:1.25em 1em;height:100%;overflow:auto}
#toc.toc2 #toctitle{margin-top:0;margin-bottom:.8rem;font-size:1.2em}
#toc.toc2>ul{font-size:.9em;margin-bottom:0}
#toc.toc2 ul ul{margin-left:0;padding-left:1em}
#toc.toc2 ul.sectlevel0 ul.sectlevel1{padding-left:0;margin-top:.5em;margin-bottom:.5em}
body.toc2.toc-right{padding-left:0;padding-right:15em}
body.toc2.toc-right #toc.toc2{border-right-width:0;border-left:1px solid #e7e7e9;left:auto;right:0}}
@media screen and (min-width:1280px){body.toc2{padding-left:20em;padding-right:0}
#toc.toc2{width:20em}
#toc.toc2 #toctitle{font-size:1.375em}
#toc.toc2>ul{font-size:.95em}
#toc.toc2 ul ul{padding-left:1.25em}
body.toc2.toc-right{padding-left:0;padding-right:20em}}
#content #toc{border:1px solid #e0e0dc;margin-bottom:1.25em;padding:1.25em;background:#f8f8f7;border-radius:4px}
#content #toc>:first-child{margin-top:0}
#content #toc>:last-child{margin-bottom:0}
#footer{max-width:none;background:rgba(0,0,0,.8);padding:1.25em}
#footer-text{color:hsla(0,0%,100%,.8);line-height:1.44}
#content{margin-bottom:.625em}
.sect1{padding-bottom:.625em}
@media screen and (min-width:768px){#content{margin-bottom:1.25em}
.sect1{padding-bottom:1.25em}}
.sect1:last-child{padding-bottom:0}
.sect1+.sect1{border-top:1px solid #e7e7e9}
#content h1>a.anchor,h2>a.anchor,h3>a.anchor,#toctitle>a.anchor,.sidebarblock>.content>.title>a.anchor,h4>a.anchor,h5>a.anchor,h6>a.anchor{position:absolute;z-index:1001;width:1.5ex;margin-left:-1.5ex;display:block;text-decoration:none!important;visibility:hidden;text-align:center;font-weight:400}
#content h1>a.anchor::before,h2>a.anchor::before,h3>a.anchor::before,#toctitle>a.anchor::before,.sidebarblock>.content>.title>a.anchor::before,h4>a.anchor::before,h5>a.anchor::before,h6>a.anchor::before{content:"\00A7";font-size:.85em;display:block;padding-top:.1em}
#content h1:hover>a.anchor,#content h1>a.anchor:hover,h2:hover>a.anchor,h2>a.anchor:hover,h3:hover>a.anchor,#toctitle:hover>a.anchor,.sidebarblock>.content>.title:hover>a.anchor,h3>a.anchor:hover,#toctitle>a.anchor:hover,.sidebarblock>.content>.title>a.anchor:hover,h4:hover>a.anchor,h4>a.anchor:hover,h5:hover>a.anchor,h5>a.anchor:hover,h6:hover>a.anchor,h6>a.anchor:hover{visibility:visible}
#content h1>a.link,h2>a.link,h3>a.link,#toctitle>a.link,.sidebarblock>.content>.title>a.link,h4>a.link,h5>a.link,h6>a.link{color:#ba3925;text-decoration:none}
#content h1>a.link:hover,h2>a.link:hover,h3>a.link:hover,#toctitle>a.link:hover,.sidebarblock>.content>.title>a.link:hover,h4>a.link:hover,h5>a.link:hover,h6>a.link:hover{color:#a53221}
details,.audioblock,.imageblock,.literalblock,.listingblock,.stemblock,.videoblock{margin-bottom:1.25em}
details{margin-left:1.25rem}
details>summary{cursor:pointer;display:block;position:relative;line-height:1.6;margin-bottom:.625rem;outline:none;-webkit-tap-highlight-color:transparent}
details>summary::-webkit-details-marker{display:none}
details>summary::before{content:"";border:solid transparent;border-left:solid;border-width:.3em 0 .3em .5em;position:absolute;top:.5em;left:-1.25rem;transform:translateX(15%)}
details[open]>summary::before{border:solid transparent;border-top:solid;border-width:.5em .3em 0;transform:translateY(15%)}
details>summary::after{content:"";width:1.25rem;height:1em;position:absolute;top:.3em;left:-1.25rem}
.admonitionblock td.content>.title,.audioblock>.title,.exampleblock>.title,.imageblock>.title,.listingblock>.title,.literalblock>.title,.stemblock>.title,.openblock>.title,.paragraph>.title,.quoteblock>.title,table.tableblock>.title,.verseblock>.title,.videoblock>.title,.dlist>.title,.olist>.title,.ulist>.title,.qlist>.title,.hdlist>.title{text-rendering:optimizeLegibility;text-align:left;font-family:"Noto Serif","DejaVu Serif",serif;font-size:1rem;font-style:italic}
table.tableblock.fit-content>caption.title{white-space:nowrap;width:0}
.paragraph.lead>p,#preamble>.sectionbody>[class=paragraph]:first-of-type p{font-size:1.21875em;line-height:1.6;color:rgba(0,0,0,.85)}
.admonitionblock>table{border-collapse:separate;border:0;background:none;width:100%}
.admonitionblock>table td.icon{text-align:center;width:80px}
.admonitionblock>table td.icon img{max-width:none}
.admonitionblock>table td.icon .title{font-weight:bold;font-family:"Open Sans","DejaVu Sans",sans-serif;text-transform:uppercase}
.admonitionblock>table td.content{padding-left:1.125em;padding-right:1.25em;border-left:1px solid #dddddf;color:rgba(0,0,0,.6);word-wrap:anywhere}
.admonitionblock>table td.content>:last-child>:last-child{margin-bottom:0}
.exampleblock>.content{border:1px solid #e6e6e6;margin-bottom:1.25em;padding:1.25em;background:#fff;border-radius:4px}
.exampleblock>.content>:first-child{margin-top:0}
.exampleblock>.content>:last-child{margin-bottom:0}
.sidebarblock{border:1px solid #dbdbd6;margin-bottom:1.25em;padding:1.25em;background:#f3f3f2;border-radius:4px}
.sidebarblock>:first-child{margin-top:0}
.sidebarblock>:last-child{margin-bottom:0}
.sidebarblock>.content>.title{color:#7a2518;margin-top:0;text-align:center}
.exampleblock>.content>:last-child>:last-child,.exampleblock>.content .olist>ol>li:last-child>:last-child,.exampleblock>.content .ulist>ul>li:last-child>:last-child,.exampleblock>.content .qlist>ol>li:last-child>:last-child,.sidebarblock>.content>:last-child>:last-child,.sidebarblock>.content .olist>ol>li:last-child>:last-child,.sidebarblock>.content .ulist>ul>li:last-child>:last-child,.sidebarblock>.content .qlist>ol>li:last-child>:last-child{margin-bottom:0}
.literalblock pre,.listingblock>.content>pre{border-radius:4px;overflow-x:auto;padding:1em;font-size:.8125em}
@media screen and (min-width:768px){.literalblock pre,.listingblock>.content>pre{font-size:.90625em}}
@media screen and (min-width:1280px){.literalblock pre,.listingblock>.content>pre{font-size:1em}}
.literalblock pre,.listingblock>.content>pre:not(.highlight),.listingblock>.content>pre[class=highlight],.listingblock>.content>pre[class^="highlight "]{background:#f7f7f8}
.literalblock.output pre{color:#f7f7f8;background:rgba(0,0,0,.9)}
.listingblock>.content{position:relative}
.listingblock code[data-lang]::before{display:none;content:attr(data-lang);position:absolute;font-size:.75em;top:.425rem;right:.5rem;line-height:1;text-transform:uppercase;color:inherit;opacity:.5}
.listingblock:hover code[data-lang]::before{display:block}
.listingblock.terminal pre .command::before{content:attr(data-prompt);padding-right:.5em;color:inherit;opacity:.5}
.listingblock.terminal pre .command:not([data-prompt])::before{content:"$"}
.listingblock pre.highlightjs{padding:0}
.listingblock pre.highlightjs>code{padding:1em;border-radius:4px}
.listingblock pre.prettyprint{border-width:0}
.prettyprint{background:#f7f7f8}
pre.prettyprint .linenums{line-height:1.45;margin-left:2em}
pre.prettyprint li{background:none;list-style-type:inherit;padding-left:0}
pre.prettyprint li code[data-lang]::before{opacity:1}
pre.prettyprint li:not(:first-child) code[data-lang]::before{display:none}
table.linenotable{border-collapse:separate;border:0;margin-bottom:0;background:none}
table.linenotable td[class]{color:inherit;vertical-align:top;padding:0;line-height:inherit;white-space:normal}
table.linenotable td.code{padding-left:.75em}
table.linenotable td.linenos,pre.pygments .linenos{border-right:1px solid;opacity:.35;padding-right:.5em;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none}
pre.pygments span.linenos{display:inline-block;margin-right:.75em}
.quoteblock{margin:0 1em 1.25em 1.5em;display:table}
.quoteblock:not(.excerpt)>.title{margin-left:-1.5em;margin-bottom:.75em}
.quoteblock blockquote,.quoteblock p{color:rgba(0,0,0,.85);font-size:1.15rem;line-height:1.75;word-spacing:.1em;letter-spacing:0;font-style:italic;text-align:justify}
.quoteblock blockquote{margin:0;padding:0;border:0}
.quoteblock blockquote::before{content:"\201c";float:left;font-size:2.75em;font-weight:bold;line-height:.6em;margin-left:-.6em;color:#7a2518;text-shadow:0 1px 2px rgba(0,0,0,.1)}
.quoteblock blockquote>.paragraph:last-child p{margin-bottom:0}
.quoteblock .attribution{margin-top:.75em;margin-right:.5ex;text-align:right}
.verseblock{margin:0 1em 1.25em}
.verseblock pre{font-family:"Open Sans","DejaVu Sans",sans-serif;font-size:1.15rem;color:rgba(0,0,0,.85);font-weight:300;text-rendering:optimizeLegibility}
.verseblock pre strong{font-weight:400}
.verseblock .attribution{margin-top:1.25rem;margin-left:.5ex}
.quoteblock .attribution,.verseblock .attribution{font-size:.9375em;line-height:1.45;font-style:italic}
.quoteblock .attribution br,.verseblock .attribution br{display:none}
.quoteblock .attribution cite,.verseblock .attribution cite{display:block;letter-spacing:-.025em;color:rgba(0,0,0,.6)}
.quoteblock.abstract blockquote::before,.quoteblock.excerpt blockquote::before,.quoteblock .quoteblock blockquote::before{display:none}
.quoteblock.abstract blockquote,.quoteblock.abstract p,.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{line-height:1.6;word-spacing:0}
.quoteblock.abstract{margin:0 1em 1.25em;display:block}
.quoteblock.abstract>.title{margin:0 0 .375em;font-size:1.15em;text-align:center}
.quoteblock.excerpt>blockquote,.quoteblock .quoteblock{padding:0 0 .25em 1em;border-left:.25em solid #dddddf}
.quoteblock.excerpt,.quoteblock .quoteblock{margin-left:0}
.quoteblock.excerpt blockquote,.quoteblock.excerpt p,.quoteblock .quoteblock blockquote,.quoteblock .quoteblock p{color:inherit;font-size:1.0625rem}
.quoteblock.excerpt .attribution,.quoteblock .quoteblock .attribution{color:inherit;font-size:.85rem;text-align:left;margin-right:0}
p.tableblock:last-child{margin-bottom:0}
td.tableblock>.content{margin-bottom:1.25em;word-wrap:anywhere}
td.tableblock>.content>:last-child{margin-bottom:-1.25em}
table.tableblock,th.tableblock,td.tableblock{border:0 solid #dedede}
table.grid-all>*>tr>*{border-width:1px}
table.grid-cols>*>tr>*{border-width:0 1px}
table.grid-rows>*>tr>*{border-width:1px 0}
table.frame-all{border-width:1px}
table.frame-ends{border-width:1px 0}
table.frame-sides{border-width:0 1px}
table.frame-none>colgroup+*>:first-child>*,table.frame-sides>colgroup+*>:first-child>*{border-top-width:0}
table.frame-none>:last-child>:last-child>*,table.frame-sides>:last-child>:last-child>*{border-bottom-width:0}
table.frame-none>*>tr>:first-child,table.frame-ends>*>tr>:first-child{border-left-width:0}
table.frame-none>*>tr>:last-child,table.frame-ends>*>tr>:last-child{border-right-width:0}
table.stripes-all>*>tr,table.stripes-odd>*>tr:nth-of-type(odd),table.stripes-even>*>tr:nth-of-type(even),table.stripes-hover>*>tr:hover{background:#f8f8f7}
th.halign-left,td.halign-left{text-align:left}
th.halign-right,td.halign-right{text-align:right}
th.halign-center,td.halign-center{text-align:center}
th.valign-top,td.valign-top{vertical-align:top}
th.valign-bottom,td.valign-bottom{vertical-align:bottom}
th.valign-middle,td.valign-middle{vertical-align:middle}
table thead th,table tfoot th{font-weight:bold}
tbody tr th{background:#f7f8f7}
tbody tr th,tbody tr th p,tfoot tr th,tfoot tr th p{color:rgba(0,0,0,.8);font-weight:bold}
p.tableblock>code:only-child{background:none;padding:0}
p.tableblock{font-size:1em}
ol{margin-left:1.75em}
ul li ol{margin-left:1.5em}
dl dd{margin-left:1.125em}
dl dd:last-child,dl dd:last-child>:last-child{margin-bottom:0}
li p,ul dd,ol dd,.olist .olist,.ulist .ulist,.ulist .olist,.olist .ulist{margin-bottom:.625em}
ul.checklist,ul.none,ol.none,ul.no-bullet,ol.no-bullet,ol.unnumbered,ul.unstyled,ol.unstyled{list-style-type:none}
ul.no-bullet,ol.no-bullet,ol.unnumbered{margin-left:.625em}
ul.unstyled,ol.unstyled{margin-left:0}
li>p:empty:only-child::before{content:"";display:inline-block}
ul.checklist>li>p:first-child{margin-left:-1em}
ul.checklist>li>p:first-child>.fa-square-o:first-child,ul.checklist>li>p:first-child>.fa-check-square-o:first-child{width:1.25em;font-size:.8em;position:relative;bottom:.125em}
ul.checklist>li>p:first-child>input[type=checkbox]:first-child{margin-right:.25em}
ul.inline{display:flex;flex-flow:row wrap;list-style:none;margin:0 0 .625em -1.25em}
ul.inline>li{margin-left:1.25em}
.unstyled dl dt{font-weight:400;font-style:normal}
ol.arabic{list-style-type:decimal}
ol.decimal{list-style-type:decimal-leading-zero}
ol.loweralpha{list-style-type:lower-alpha}
ol.upperalpha{list-style-type:upper-alpha}
ol.lowerroman{list-style-type:lower-roman}
ol.upperroman{list-style-type:upper-roman}
ol.lowergreek{list-style-type:lower-greek}
.hdlist>table,.colist>table{border:0;background:none}
.hdlist>table>tbody>tr,.colist>table>tbody>tr{background:none}
td.hdlist1,td.hdlist2{vertical-align:top;padding:0 .625em}
td.hdlist1{font-weight:bold;padding-bottom:1.25em}
td.hdlist2{word-wrap:anywhere}
.literalblock+.colist,.listingblock+.colist{margin-top:-.5em}
.colist td:not([class]):first-child{padding:.4em .75em 0;line-height:1;vertical-align:top}
.colist td:not([class]):first-child img{max-width:none}
.colist td:not([class]):last-child{padding:.25em 0}
.thumb,.th{line-height:0;display:inline-block;border:4px solid #fff;box-shadow:0 0 0 1px #ddd}
.imageblock.left{margin:.25em .625em 1.25em 0}
.imageblock.right{margin:.25em 0 1.25em .625em}
.imageblock>.title{margin-bottom:0}
.imageblock.thumb,.imageblock.th{border-width:6px}
.imageblock.thumb>.title,.imageblock.th>.title{padding:0 .125em}
.image.left,.image.right{margin-top:.25em;margin-bottom:.25em;display:inline-block;line-height:0}
.image.left{margin-right:.625em}
.image.right{margin-left:.625em}
a.image{text-decoration:none;display:inline-block}
a.image object{pointer-events:none}
sup.footnote,sup.footnoteref{font-size:.875em;position:static;vertical-align:super}
sup.footnote a,sup.footnoteref a{text-decoration:none}
sup.footnote a:active,sup.footnoteref a:active{text-decoration:underline}
#footnotes{padding-top:.75em;padding-bottom:.75em;margin-bottom:.625em}
#footnotes hr{width:20%;min-width:6.25em;margin:-.25em 0 .75em;border-width:1px 0 0}
#footnotes .footnote{padding:0 .375em 0 .225em;line-height:1.3334;font-size:.875em;margin-left:1.2em;margin-bottom:.2em}
#footnotes .footnote a:first-of-type{font-weight:bold;text-decoration:none;margin-left:-1.05em}
#footnotes .footnote:last-of-type{margin-bottom:0}
#content #footnotes{margin-top:-.625em;margin-bottom:0;padding:.75em 0}
div.unbreakable{page-break-inside:avoid}
.big{font-size:larger}
.small{font-size:smaller}
.underline{text-decoration:underline}
.overline{text-decoration:overline}
.line-through{text-decoration:line-through}
.aqua{color:#00bfbf}
.aqua-background{background:#00fafa}
.black{color:#000}
.black-background{background:#000}
.blue{color:#0000bf}
.blue-background{background:#0000fa}
.fuchsia{color:#bf00bf}
.fuchsia-background{background:#fa00fa}
.gray{color:#606060}
.gray-background{background:#7d7d7d}
.green{color:#006000}
.green-background{background:#007d00}
.lime{color:#00bf00}
.lime-background{background:#00fa00}
.maroon{color:#600000}
.maroon-background{background:#7d0000}
.navy{color:#000060}
.navy-background{background:#00007d}
.olive{color:#606000}
.olive-background{background:#7d7d00}
.purple{color:#600060}
.purple-background{background:#7d007d}
.red{color:#bf0000}
.red-background{background:#fa0000}
.silver{color:#909090}
.silver-background{background:#bcbcbc}
.teal{color:#006060}
.teal-background{background:#007d7d}
.white{color:#bfbfbf}
.white-background{background:#fafafa}
.yellow{color:#bfbf00}
.yellow-background{background:#fafa00}
span.icon>.fa{cursor:default}
a span.icon>.fa{cursor:inherit}
.admonitionblock td.icon [class^="fa icon-"]{font-size:2.5em;text-shadow:1px 1px 2px rgba(0,0,0,.5);cursor:default}
.admonitionblock td.icon .icon-note::before{content:"\f05a";color:#19407c}
.admonitionblock td.icon .icon-tip::before{content:"\f0eb";text-shadow:1px 1px 2px rgba(155,155,0,.8);color:#111}
.admonitionblock td.icon .icon-warning::before{content:"\f071";color:#bf6900}
.admonitionblock td.icon .icon-caution::before{content:"\f06d";color:#bf3400}
.admonitionblock td.icon .icon-important::before{content:"\f06a";color:#bf0000}
.conum[data-value]{display:inline-block;color:#fff!important;background:rgba(0,0,0,.8);border-radius:50%;text-align:center;font-size:.75em;width:1.67em;height:1.67em;line-height:1.67em;font-family:"Open Sans","DejaVu Sans",sans-serif;font-style:normal;font-weight:bold}
.conum[data-value] *{color:#fff!important}
.conum[data-value]+b{display:none}
.conum[data-value]::after{content:attr(data-value)}
pre .conum[data-value]{position:relative;top:-.125em}
b.conum *{color:inherit!important}
.conum:not([data-value]):empty{display:none}
dt,th.tableblock,td.content,div.footnote{text-rendering:optimizeLegibility}
h1,h2,p,td.content,span.alt,summary{letter-spacing:-.01em}
p strong,td.content strong,div.footnote strong{letter-spacing:-.005em}
p,blockquote,dt,td.content,span.alt,summary{font-size:1.0625rem}
p{margin-bottom:1.25rem}
.sidebarblock p,.sidebarblock dt,.sidebarblock td.content,p.tableblock{font-size:1em}
.exampleblock>.content{background:#fffef7;border-color:#e0e0dc;box-shadow:0 1px 4px #e0e0dc}
.print-only{display:none!important}
@page{margin:1.25cm .75cm}
@media print{*{box-shadow:none!important;text-shadow:none!important}
html{font-size:80%}
a{color:inherit!important;text-decoration:underline!important}
a.bare,a[href^="#"],a[href^="mailto:"]{text-decoration:none!important}
a[href^="http:"]:not(.bare)::after,a[href^="https:"]:not(.bare)::after{content:"(" attr(href) ")";display:inline-block;font-size:.875em;padding-left:.25em}
abbr[title]{border-bottom:1px dotted}
abbr[title]::after{content:" (" attr(title) ")"}
pre,blockquote,tr,img,object,svg{page-break-inside:avoid}
thead{display:table-header-group}
svg{max-width:100%}
p,blockquote,dt,td.content{font-size:1em;orphans:3;widows:3}
h2,h3,#toctitle,.sidebarblock>.content>.title{page-break-after:avoid}
#header,#content,#footnotes,#footer{max-width:none}
#toc,.sidebarblock,.exampleblock>.content{background:none!important}
#toc{border-bottom:1px solid #dddddf!important;padding-bottom:0!important}
body.book #header{text-align:center}
body.book #header>h1:first-child{border:0!important;margin:2.5em 0 1em}
body.book #header .details{border:0!important;display:block;padding:0!important}
body.book #header .details span:first-child{margin-left:0!important}
body.book #header .details br{display:block}
body.book #header .details br+span::before{content:none!important}
body.book #toc{border:0!important;text-align:left!important;padding:0!important;margin:0!important}
body.book #toc,body.book #preamble,body.book h1.sect0,body.book .sect1>h2{page-break-before:always}
.listingblock code[data-lang]::before{display:block}
#footer{padding:0 .9375em}
.hide-on-print{display:none!important}
.print-only{display:block!important}
.hide-for-print{display:none!important}
.show-for-print{display:inherit!important}}
@media amzn-kf8,print{#header>h1:first-child{margin-top:1.25rem}
.sect1{padding:0!important}
.sect1+.sect1{border:0}
#footer{background:none}
#footer-text{color:rgba(0,0,0,.6);font-size:.9em}}
@media amzn-kf8{#header,#content,#footnotes,#footer{padding:0}}
</style>
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/styles/github.min.css">
</head>
<body class="article toc2 toc-left data-line-1">
<div id="header">
<h1>Processamento Digital de Imagens</h1>
<div class="details">
<span id="author" class="author">Igor Barbosa</span><br>
<span id="email" class="email"><a href="mailto:igor.barbosa.705@ufrn.edu.br" data-href="mailto:igor.barbosa.705@ufrn.edu.br">igor.barbosa.705@ufrn.edu.br</a></span><br>
<span id="revdate">Última atualização 25/10/2022</span>
</div>
<div id="toc" class="toc2">
<div id="toctitle">Table of Contents</div>
<ul class="sectlevel1">
<li><a href="#_1_regions">1. Regions</a></li>
<li><a href="#_2_trocaregioes">2. Trocaregioes</a></li>
<li><a href="#_3_labeling">3. Labeling</a>
<ul class="sectlevel2">
<li><a href="#_3_1_problemática">3.1. Problemática</a></li>
</ul>
</li>
<li><a href="#_4_equalize">4. Equalize</a></li>
<li><a href="#_5_motiondetector">5. Motiondetector</a>
<ul class="sectlevel2">
<li><a href="#_5_1_aidentudetector">5.1. Aidentudetector</a></li>
</ul>
</li>
<li><a href="#_6_laplgauss">6. Laplgauss</a></li>
</ul>
</div>
</div>
<div id="content">
<div id="preamble">
<div class="sectionbody">
<div class="paragraph data-line-9">
<p>A presente página sofrerá alterações no decorrer do semestre.</p>
</div>
</div>
</div>
<div class="sect1 data-line-12">
<h2 id="_1_regions">1. Regions</h2>
<div class="sectionbody">
<div class="paragraph data-line-13">
<p>Neste primeiro exercício pedia-se:</p>
</div>
<div class="exampleblock data-line-14">
<div class="content">
<div class="paragraph data-line-15">
<p>Utilizando o programa <em>exemplos/pixels.cpp</em> como referência, implemente um programa <strong>regions.cpp</strong>. Esse programa deverá solicitar ao usuário as coordenadas de dois pontos <strong>P1</strong> e <strong>P2</strong> localizados dentro dos limites do tamanho da imagem e exibir que lhe for fornecida. Entretanto, a região definida pelo retângulo de vértices opostos definidos pelos pontos <strong>P1</strong> e <strong>P2</strong> será exibida com o <strong>negativo</strong> da imagem na região correspondente.</p>
</div>
</div>
</div>
<div class="paragraph data-line-18">
<p>A solução da problemática está demonstrada abaixo. O código foi desenvolvido utilizando a linguagem <em>Python</em>.</p>
</div>
<div class="listingblock data-line-0">
<div class="title">Código completo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  regions.py
# Autor: Igor Barbosa
# Última atualização : 23/10/2022

import cv2 as cv

img = cv.imread('./1.regions/OpenCV_Logo.png',cv.IMREAD_GRAYSCALE)
cv.namedWindow('Imagem selecionada')
cv.imshow('Imagem selecionada', img)

height, width = img.shape[:2]
print("A altura da imagem é: ", height)
print("A largura da imagem é: ", width)


while not (px1 := input('Coordenada X do P1: ')).isdigit() or (px1:=int(px1)) &lt; 0 or px1 &gt; height:
    print('Valor INVÁLIDO')
while not (py1 := input('Coordenada Y do P1: ')).isdigit() or (py1:=int(py1)) &lt; 0 or py1 &gt; width:
    print('Valor INVÁLIDO')
while not (px2 := input('Coordenada X do P2: ')).isdigit() or (px2:=int(px2)) &lt; 0 or px2 &gt; height:
    print('Valor INVÁLIDO')
while not (py2 := input('Coordenada Y do P2: ')).isdigit() or (py2:=int(px2)) &lt; 0 or py2 &gt; width:
    print('Valor INVÁLIDO')


for x in range (min(px1,px2),max(px1,px2)):
    for y in range (min(py1,py2),max(py1,py2)):
        img[x,y] = 255 - img[x,y]


cv.namedWindow('Resultado') 
cv.imshow('Resultado', img)  
cv.waitKey()
cv.imwrite('./1.regions/Output.png',img)
cv.destroyAllWindows()</code></pre>
</div>
</div>
<div class="paragraph data-line-26">
<p>Para separarmos a imagem em 4 quadrantes é necessário descobrirmos o centro, por isso, nesta etapa do programa
Agora, vamos destrinchar o programa, começando pela importação da biblioteca do OpenCV.</p>
</div>
<div class="listingblock data-line-31">
<div class="title">Importação da biblioteca do OpenCV</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  regions.py
# Autor: Igor Barbosa
# Última atualização : 23/10/2022

import cv2 as cv</code></pre>
</div>
</div>
<div class="paragraph data-line-39">
<p>Após a declaração da biblioteca, temos a importação da imagem que será tratada pelo código. A imagem está representada pela <em>Figure 1</em>, se trata do logo do OpenCV. Podemos perceber que a imagem encontra-se colorida. Por isso, ao carregarmos a figura já a transformamos para a escala de cinza.</p>
</div>
<div class="listingblock data-line-43">
<div class="title">Entrada da imagem</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">img = cv.imread('./1.regions/OpenCV_Logo.png',cv.IMREAD_GRAYSCALE)
cv.namedWindow('Imagem selecionada')
cv.imshow('Imagem selecionada', img)</code></pre>
</div>
</div>
<div class="imageblock data-line-51">
<div class="content">
<img src="./1.regions/OpenCV_Logo.png" alt="OpenCV Logo">
</div>
<div class="title">Figure 1. Imagem de entrada : Logo do OpenCV colorido.</div>
</div>
<div class="paragraph data-line-53">
<p>Após a entrada da imagem, temos a parte a medição do tamanho da mesma e a exibição das medições de altura e largura para o usuário definir os pontos que serão transformados na parte negativa.</p>
</div>
<div class="listingblock data-line-57">
<div class="title">Tamanho da imagem</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">height, width = img.shape[:2]
print("A altura da imagem é: ", height)
print("A largura da imagem é: ", width)</code></pre>
</div>
</div>
<div class="paragraph data-line-63">
<p>Finalmente, o usuário poderá colocar as coordenadas dos pontos <em>P1</em> e <em>P2</em>. Utilizamos uma lógica tal qual o usuário só consiga inserir valores das coordenadas dos pontos que sejam válidos. Caso ele insira um valor inválido, ficará em um <em>loop</em> até que insira um valor aceitável. Este valor aceitável está relacionado com as medidas da imagem mensuradas anteriormente. Caso o usuário insira um valor que não seja um número ou um número que seja menor que 0 ou maior que o tamanho da imagem (um ponto que saia das dimensões da imagem), não será aceito.</p>
</div>
<div class="listingblock data-line-67">
<div class="title">Inserção dos pontos P1 e P2</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">while not (px1 := input('Coordenada X do P1: ')).isdigit() or (px1:=int(px1)) &lt; 0 or px1 &gt; height:
    print('Valor INVÁLIDO')
while not (py1 := input('Coordenada Y do P1: ')).isdigit() or (py1:=int(py1)) &lt; 0 or py1 &gt; width:
    print('Valor INVÁLIDO')
while not (px2 := input('Coordenada X do P2: ')).isdigit() or (px2:=int(px2)) &lt; 0 or px2 &gt; height:
    print('Valor INVÁLIDO')
while not (py2 := input('Coordenada Y do P2: ')).isdigit() or (py2:=int(px2)) &lt; 0 or py2 &gt; width:
    print('Valor INVÁLIDO')</code></pre>
</div>
</div>
<div class="paragraph data-line-78">
<p>Com os pontos corretos e definidos, utilizamos dois laços, um para cada eixo da imagem, para que percorra toda a área selecinada e aplique o negativo na mesma. Para aplicar o negativo, basta pegar o valor do <em>pixel</em> de entrada e substrair de 255 (valor que representa o branco), assim como demonstrado a seguir.</p>
</div>
<div class="listingblock data-line-82">
<div class="title">Tratamento da área negativa da imagem</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">for x in range (min(px1,px2),max(px1,px2)):
    for y in range (min(py1,py2),max(py1,py2)):
        img[x,y] = 255 - img[x,y]</code></pre>
</div>
</div>
<div class="paragraph data-line-88">
<p>Como podemos ver, a área negativa da imagem tratada fora sobrescrita na imagem tratada para a escala cinza.</p>
</div>
<div class="paragraph data-line-90">
<p>Por fim, temos o encerramento do programa e o armazenamento da imagem tratada.</p>
</div>
<div class="listingblock data-line-94">
<div class="title">Encerramento e armazenamento da imagem tratada</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">cv.namedWindow('Resultado')
cv.imshow('Resultado', img)
cv.waitKey()
cv.imwrite('./1.regions/Output.png',img)
cv.destroyAllWindows()</code></pre>
</div>
</div>
<div class="paragraph data-line-102">
<p>Para os pontos definidos <em>P1(10,10)</em> e <em>P2(250,250)</em> temos como saída a Figure 2.</p>
</div>
<div class="imageblock data-line-105">
<div class="content">
<img src="./1.regions/Output.png" alt="Output">
</div>
<div class="title">Figure 2. Saída do código para os pontos P1(10,10) e P2(250,250).</div>
</div>
</div>
</div>
<div class="sect1 data-line-107">
<h2 id="_2_trocaregioes">2. Trocaregioes</h2>
<div class="sectionbody">
<div class="paragraph data-line-108">
<p>Neste segundo exercício pedia-se:</p>
</div>
<div class="exampleblock data-line-109">
<div class="content">
<div class="paragraph data-line-110">
<p>Utilizando o programa <em>exemplos/pixels.cpp</em> como referência, implemente um programa <strong>trocaregioes.cpp</strong>. Seu programa deverá trocar os quadrantes em diagonal na imagem. Explore o uso da classe <em>Mat</em> e seus construtores para criar as regiões que serão trocadas.</p>
</div>
</div>
</div>
<div class="paragraph data-line-113">
<p>A solução da problemática está demonstrada abaixo. Como o código foi desenvolvido utilizando a linguagem <em>Python</em>, a classe <em>Mat</em> não fora utilizada.</p>
</div>
<div class="listingblock data-line-0">
<div class="title">Código completo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  trocaregioes.py
# Autor: Igor Barbosa
# Última atualização : 24/10/2022

import cv2 as cv
import numpy as np

img = cv.imread('./2.trocaregioes/OpenCV_Logo.png',cv.IMREAD_COLOR)
cv.namedWindow('Imagem selecionada')
cv.imshow('Imagem selecionada', img)


height, width = img.shape[:2]
h_centro, w_centro = height//2 , width//2
#print(height, width)                       #teste
#print(h_centro, w_centro)


q1 = img[0:h_centro, w_centro:width]
#h1, w1 = q1.shape[:2]                      #teste Q1
#print(h1,w1)
#cv.namedWindow('Quadrante 1')
#cv.imshow('Quadrante 1', q1)

q2 = img[0:h_centro, 0:w_centro]
#h2, w2 = q2.shape[:2]                      #teste Q2
#print(h2,w2)
#cv.namedWindow('Quadrante 2')
#cv.imshow('Quadrante 2', q2)

q3 = img[h_centro:height, 0:w_centro]
#h3, w3 = q3.shape[:2]                      #teste Q3
#print(h3,w3)
#cv.namedWindow('Quadrante 3')
#cv.imshow('Quadrante 3', q3)

q4 = img[h_centro:height, w_centro:width]
#h4, w4 = q4.shape[:2]                      #teste Q4
#print(h4,w4)
#cv.namedWindow('Quadrante 4')
#cv.imshow('Quadrante 4', q4)

q43 = np.concatenate((q4,q3),axis=1)
q12 = np.concatenate((q1,q2),axis=1)
img = np.concatenate((q43,q12),axis=0)


cv.namedWindow('Resultado') 
cv.imshow('Resultado', img)  
cv.waitKey()
cv.imwrite('./2.trocaregioes/Output.png',img)
cv.imwrite('./2.trocaregioes/Quadrante1.png',q1)
cv.imwrite('./2.trocaregioes/Quadrante2.png',q2)
cv.imwrite('./2.trocaregioes/Quadrante3.png',q3)
cv.imwrite('./2.trocaregioes/Quadrante4.png',q4)
cv.destroyAllWindows()</code></pre>
</div>
</div>
<div class="paragraph data-line-121">
<p>Primeiramente, temos a declaração das bibliotecas OpenCV e NumPy. A primeira será utilizada para o trabalho com a imagem, que por sinal será a mesma do Exercício 1, e a biblioteca NumPy será utilizada para se trabalhar com as matrizes das divisões da imagem.</p>
</div>
<div class="paragraph data-line-123">
<p>Após a declaração das bibliotecas, temos o passo de carregar a imagem, este procedimento é o mesmo do Exercício 1.</p>
</div>
<div class="listingblock data-line-127">
<div class="title">Inicialização do código</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2 as cv
import numpy as np

img = cv.imread('./2.trocaregioes/OpenCV_Logo.png',cv.IMREAD_COLOR)
cv.namedWindow('Imagem selecionada')
cv.imshow('Imagem selecionada', img)</code></pre>
</div>
</div>
<div class="paragraph data-line-136">
<p>Para dividirmos a imagem em quatro quadrantes, optamos por achar um ponto em cada eixo que tivesse a característica central. Para isso, como demonstrado abaixo, pegamos as dimensões da imagem e usamos o operador <strong>//</strong> no qual retorna um valor inteiro do resultado da divisão, por isso que dizemos um ponto com "característica central", pois, pode não ser o centro propriamente dito.</p>
</div>
<div class="listingblock data-line-140">
<div class="title">Procura dos pontos centrais dos eixos</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">height, width = img.shape[:2]
h_centro, w_centro = height//2 , width//2</code></pre>
</div>
</div>
<div class="paragraph data-line-145">
<p>Com os pontos centrais, dividimos a imagem em quatro partes:</p>
</div>
<table class="tableblock frame-all grid-all stretch data-line-148">
<caption class="title">Table 1. Limites dos quadrantes</caption>
<colgroup>
<col style="width: 33.3333%;">
<col style="width: 33.3333%;">
<col style="width: 33.3334%;">
</colgroup>
<thead>
<tr>
<th class="tableblock halign-left valign-top">Quadrante</th>
<th class="tableblock halign-left valign-top">Y</th>
<th class="tableblock halign-left valign-top">X</th>
</tr>
</thead>
<tbody>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quadrante 1</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do centro até o tamanho total da largura da imagem</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do zero até o ponto central</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quadrante 2</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do zero até o ponto central</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do zero até o ponto central</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quadrante 3</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do zero até o ponto central</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do centro até o tamanho total da altura da imagem</p></td>
</tr>
<tr>
<td class="tableblock halign-left valign-top"><p class="tableblock">Quadrante 4</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do centro até o tamanho total da largura da imagem</p></td>
<td class="tableblock halign-left valign-top"><p class="tableblock">Do centro até o tamanho total da altura da imagem</p></td>
</tr>
</tbody>
</table>
<div class="paragraph data-line-168">
<p>Podemos perceber que os quadrantes adotados seguem o padrão da <em>Figure 3</em>. Cabe a destacarmos que o <em>X</em> e o <em>Y</em> da Figura não são os adotados no programa. Colocamos a esta ilustração apenas para facilitar o entendimento das divisões dos quadrantes, no caso, o sentido da divisão. Os eixos <em>X</em> e <em>Y</em> continuam sendo os adotados pelo OpenCV e padrão no Processamento Digital de Imagens.</p>
</div>
<div class="imageblock data-line-171">
<div class="content">
<img src="./imagens/Quadrantes.png" alt="Quadrantes">
</div>
<div class="title">Figure 3. Ilustração de base para o entendimento da divisão da imagem.</div>
</div>
<div class="paragraph data-line-173">
<p>A parte do programa dedicado em dividir os quadrantes é esta:</p>
</div>
<div class="listingblock data-line-177">
<div class="title">Divisão dos quadrantes</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">q1 = img[0:h_centro, w_centro:width]
#h1, w1 = q1.shape[:2]                      #teste Q1
#print(h1,w1)
#cv.namedWindow('Quadrante 1')
#cv.imshow('Quadrante 1', q1)

q2 = img[0:h_centro, 0:w_centro]
#h2, w2 = q2.shape[:2]                      #teste Q2
#print(h2,w2)
#cv.namedWindow('Quadrante 2')
#cv.imshow('Quadrante 2', q2)

q3 = img[h_centro:height, 0:w_centro]
#h3, w3 = q3.shape[:2]                      #teste Q3
#print(h3,w3)
#cv.namedWindow('Quadrante 3')
#cv.imshow('Quadrante 3', q3)

q4 = img[h_centro:height, w_centro:width]
#h4, w4 = q4.shape[:2]                      #teste Q4
#print(h4,w4)
#cv.namedWindow('Quadrante 4')
#cv.imshow('Quadrante 4', q4)</code></pre>
</div>
</div>
<div class="paragraph data-line-203">
<p>Os testes são para observar se os quadrantes estão divididos da forma certa.</p>
</div>
<div class="paragraph data-line-205">
<p>Com os quadrantes divididos, realizamos a troca dos mesmos. Para tal, usamos a biblioteca NumPy, mais precisamente a função <em>numpy.concatenate</em>, para juntar as matrizes formadas.</p>
</div>
<div class="listingblock data-line-209">
<div class="title">Troca dos quadrantes</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">q43 = np.concatenate((q4,q3),axis=1)
q12 = np.concatenate((q1,q2),axis=1)
img = np.concatenate((q43,q12),axis=0)</code></pre>
</div>
</div>
<div class="paragraph data-line-215">
<p>Na primeira linha da parte do código mostrado acima, juntamos horizontalmente (demonstrado por <em>axis=1</em>) os quadrantes 4 e 3. Na segunda linha, os quadrantes 1 e 2. Por fim, juntamos verticalmente as duas matrizes formadas anteriormente, tendo como consequência a troca total dos quadrantes.</p>
</div>
<div class="paragraph data-line-217">
<p>Para uma entrada sendo a imagem da <em>Figure 1</em>, que é a logo do OpenCV colorida, teremos como saída a <em>Figure 4</em>.</p>
</div>
<div class="imageblock data-line-220">
<div class="content">
<img src="./2.trocaregioes/Output.png" alt="Output">
</div>
<div class="title">Figure 4. Ilustração de base para o entendimento da divisão da imagem.</div>
</div>
</div>
</div>
<div class="sect1 data-line-222">
<h2 id="_3_labeling">3. Labeling</h2>
<div class="sectionbody">
<div class="paragraph data-line-223">
<p>Neste terceiro exercício pedia-se:</p>
</div>
<div class="exampleblock data-line-224">
<div class="content">
<div class="paragraph data-line-225">
<p>Aprimore o algoritmo de contagem apresentado para identificar regiões com ou sem buracos internos que existam na cena. Assuma que objetos com mais de um buraco podem existir. Inclua suporte no seu algoritmo para não contar bolhas que tocam as bordas da imagem. Não se pode presumir, a priori, que elas tenham buracos ou não.</p>
</div>
</div>
</div>
<div class="paragraph data-line-228">
<p>A solução da problemática está demonstrada abaixo. O código foi desenvolvido utilizando a linguagem <em>Python</em>.</p>
</div>
<div class="listingblock data-line-0">
<div class="title">Código completo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  labeling.py
# Autor: Igor Barbosa
# Última atualização : 24/10/2022

import cv2 as cv

img = cv.imread('./3.labeling/bolhas.png',cv.IMREAD_GRAYSCALE)
cv.namedWindow('Imagem selecionada')
cv.imshow('Imagem selecionada', img)

height, width = img.shape[:2]
print("A altura da imagem é: ", height)
print("A largura da imagem é: ", width)

#retirando as bolhas das bordas
#bordas verticais
for y in [0,width-1]:
    for x in range (height):
        if img[x,y] == 255:
            cv.floodFill(img, None, (y,x), 0)
#bordas horizontais
for x in [0,height-1]:
    for y in range (width):
        if img[x,y] == 255:
            cv.floodFill(img, None, (y,x), 0)
cv.imwrite('./3.labeling/bolhas_bordas_retiradas.png',img)
cv.namedWindow('Bordas Retiradas') 
cv.imshow('Bordas Retiradas', img)  

#contando o número total de bolhas
nbolhas = 0
for y in range (width):
    for x in range (height):
        if img[x,y] == 255:
            nbolhas = nbolhas + 1
            cv.floodFill(img, None, (y,x), nbolhas)
cv.imwrite('./3.labeling/bolhas_pintadas.png',img)
cv.namedWindow('Bolhas pintadas') 
cv.imshow('Bolhas pintadas', img)  

#contando o número total de bolhas com buracos
cv.floodFill(img, None, (0,0), 255)
cv.imwrite('./3.labeling/fundo_pintado.png',img)
cv.namedWindow('Fundo pintado') 
cv.imshow('Fundo pintado', img) 

nbolhasburacos = 0
for y in range (width):
    for x in range (height):
        if img[x,y] == 0:
            nbolhasburacos = nbolhasburacos + 1
            cv.floodFill(img, None, (y,x), 255)
cv.imwrite('./3.labeling/buracos_pintados.png',img)
cv.namedWindow('Buracos pintados') 
cv.imshow('Buracos pintados', img) 

print(f'Número total de bolhas: {nbolhas}')
print(f'Número total de bolhas com buracos: {nbolhasburacos}')

cv.waitKey()
cv.destroyAllWindows()</code></pre>
</div>
</div>
<div class="paragraph data-line-236">
<p>Para este exercício utilizamos como entrada a imagem da <em>Figure 5</em>.</p>
</div>
<div class="imageblock data-line-239">
<div class="content">
<img src="./3.labeling/bolhas.png" alt="bolhas">
</div>
<div class="title">Figure 5. Imagem de entrada.</div>
</div>
<div class="paragraph data-line-241">
<p>Como podemos ver, apesar de termos as presenças das bolhas que são "cortadas" pelas bolhas, não podemos abstrair se as mesmas possuem buracos ou não. Então, teremos que desconsiderá-las.</p>
</div>
<div class="paragraph data-line-243">
<p>Para tal, as bolhas estão com o nível máximo de brilho (255), portanto, para eliminarmos as bolhas das bordas, basta andarmos pelas bordas e quando existir um pixel com o nível 255, aplicamos <em>cv.floodFill</em> no mesmo pixel, com a cor de preenchimento sendo o nível 0.</p>
</div>
<div class="listingblock data-line-247">
<div class="title">Parte do código destinada a retirar as bolhas das bordas</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">height, width = img.shape[:2]
print("A altura da imagem é: ", height)
print("A largura da imagem é: ", width)

#retirando as bolhas das bordas
#bordas verticais
for y in [0,width-1]:
    for x in range (height):
        if img[x,y] == 255:
            cv.floodFill(img, None, (y,x), 0)
#bordas horizontais
for x in [0,height-1]:
    for y in range (width):
        if img[x,y] == 255:
            cv.floodFill(img, None, (y,x), 0)
cv.imwrite('./3.labeling/bolhas_bordas_retiradas.png',img)
cv.namedWindow('Bordas Retiradas')
cv.imshow('Bordas Retiradas', img)</code></pre>
</div>
</div>
<div class="paragraph data-line-268">
<p>Como resultado desta parte do código temos a <em>Figure 6</em>.</p>
</div>
<div class="imageblock data-line-271">
<div class="content">
<img src="./3.labeling/bolhas_bordas_retiradas.png" alt="bolhas bordas retiradas">
</div>
<div class="title">Figure 6. Imagem de entrada sem as bolhas das bordas.</div>
</div>
<div class="paragraph data-line-273">
<p>Agora, fazemos um laço que irá percorrer toda a imagem, quando tivermos os níveis 255, significa que "estaremos no objeto/bolha". Utilizando novamente o <em>cv.floodFill</em>, iremos aplicar uma nova tonalidade para a bolha e será única. Utilizando deste detalhe, somos capazes de contar a quantidade de bolhas presentes na imagem.</p>
</div>
<div class="paragraph data-line-275">
<p>Na parte do código abaixo, temos a variável <strong>nbolhas</strong>, que se inicia com 0. Quando a cor branca (255) é detectada, adicionamos 1 na variável e o número vigente armazenado em <strong>nbolhas</strong> será a nova tonalidade do objeto detectado.</p>
</div>
<div class="listingblock data-line-279">
<div class="title">Parte do código destinada a contar o total de bolhas</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">#contando o número total de bolhas
nbolhas = 0
for y in range (width):
    for x in range (height):
        if img[x,y] == 255:
            nbolhas = nbolhas + 1
            cv.floodFill(img, None, (y,x), nbolhas)
cv.imwrite('./3.labeling/bolhas_pintadas.png',img)
cv.namedWindow('Bolhas pintadas')
cv.imshow('Bolhas pintadas', img)</code></pre>
</div>
</div>
<div class="paragraph data-line-292">
<p>No final da contagem teremos o número total de bolhas e percebemos que, na imagem de saída nesta etapa do programa, a tonalidade das bolhas vai ficando mais clara conforme visto na <em>Figure 7</em>.</p>
</div>
<div class="imageblock data-line-295">
<div class="content">
<img src="./3.labeling/bolhas_pintadas.png" alt="bolhas pintadas">
</div>
<div class="title">Figure 7. Bolhas com tonalidades distintas.</div>
</div>
<div class="paragraph data-line-297">
<p>Com todas as bolhas endereçadas e sem a utilização do branco (255) na imagem, fazemos uma mudança de cor no fundo, que no caso é preto (0), para branco (255). Para garantirmos esta mudança, escolhemos algum ponto da borda, pois, com o tratamento de retirada das bolhas das bordas, temos a certeza que nesses locais não existirão pontos com o nível de brilho 255.</p>
</div>
<div class="listingblock data-line-301">
<div class="title">Mudança do fundo para a cor branca (255)</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">#contando o número total de bolhas com buracos
cv.floodFill(img, None, (0,0), 255)
cv.imwrite('./3.labeling/fundo_pintado.png',img)
cv.namedWindow('Fundo pintado')
cv.imshow('Fundo pintado', img)</code></pre>
</div>
</div>
<div class="paragraph data-line-309">
<p>Escolhemos o ponto (0,0) e aplicamos a função <em>cv.floodFill</em> novamente. Tendo como saída a <em>Figure 8</em>.</p>
</div>
<div class="imageblock data-line-312">
<div class="content">
<img src="./3.labeling/fundo_pintado.png" alt="fundo pintado">
</div>
<div class="title">Figure 8. Mudança do fundo para a cor branca (255).</div>
</div>
<div class="paragraph data-line-314">
<p>Neste momento, as únicas regiões com a cor preta (0) são os buracos das bolhas. Portanto, utilizando uma lógica idêntica à utilizada para contar as bolhas, contaremos as bolhas com buracos.</p>
</div>
<div class="listingblock data-line-318">
<div class="title">Contagem das bolhas com buracos.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">nbolhasburacos = 0
for y in range (width):
    for x in range (height):
        if img[x,y] == 0:
            nbolhasburacos = nbolhasburacos + 1
            cv.floodFill(img, None, (y,x), 255)</code></pre>
</div>
</div>
<div class="paragraph data-line-327">
<p>Por fim, temos como resultado:</p>
</div>
<div class="listingblock data-line-330">
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">Número total de bolhas: 21
Número total de bolhas com buracos: 7</code></pre>
</div>
</div>
<div class="imageblock data-line-336">
<div class="content">
<img src="./3.labeling/buracos_pintados.png" alt="buracos pintados">
</div>
<div class="title">Figure 9. Imagem final do programa labeling.py.</div>
</div>
<div class="sect2 data-line-338">
<h3 id="_3_1_problemática">3.1. Problemática</h3>
<div class="paragraph data-line-339">
<p>Ainda neste exercício, nos é levantado a seguinte problemática:</p>
</div>
<div class="exampleblock data-line-340">
<div class="content">
<div class="paragraph data-line-341">
<p>Observando-se o programa labeling.cpp como exemplo, é possível verificar que caso existam mais de 255 objetos na cena, o processo de rotulação poderá ficar comprometido. Identifique a situação em que isso ocorre e proponha uma solução para este problema.</p>
</div>
</div>
</div>
<div class="paragraph data-line-343">
<p>Acreditamos que se passar dos 254 objetos já teremos problemas, pois, uma tonalidade estará ligado aos buracos e a outra ao fundo.</p>
</div>
<div class="paragraph data-line-345">
<p>A situação em que isso pode ocorrer é uma cena ou imagem relativamente grande com a presença de objetos consideravelmente pequenos, com estas duas premissas, teremos a grande chance de passarmos dos 254 objetos.</p>
</div>
<div class="paragraph data-line-347">
<p>Uma forma de contornar esta problemática, seria trabalharmos com cores, aumentando a quantidade de objetos para <em>256x256x256-2 =</em> <strong>16.777.214</strong>. Entretanto, ao trabalharmos com cores, estaríamos triplicando a quantidade de informação, pois, cada pixel agora carregaria 3 bytes de dados.</p>
</div>
<div class="paragraph data-line-349">
<p>Outra forma que talvez seja menos custosa computacionalmente, seria aumentar a resolução da escala de cinza, no caso, trabalhando com 2 bytes, agora duplicaríamos o volume de dados para conseguirmos trabalhar com <em>256x256-2 =</em> <strong>65.536</strong> objetos.</p>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-352">
<h2 id="_4_equalize">4. Equalize</h2>
<div class="sectionbody">
<div class="paragraph data-line-353">
<p>Neste quarto exercício pedia-se:</p>
</div>
<div class="exampleblock data-line-354">
<div class="content">
<div class="paragraph data-line-355">
<p>Utilizando o programa <em>exemplos/histogram.cpp</em> como referência, implemente um programa <strong>equalize.cpp</strong>. Este deverá, para cada imagem capturada, realizar a equalização do histogram antes de exibir a imagem. Teste sua implementação apontando a câmera para ambientes com iluminações variadas e observando o efeito gerado. Assuma que as imagens processadas serão em tons de cinza.</p>
</div>
</div>
</div>
<div class="paragraph data-line-358">
<p>A solução da problemática está demonstrada abaixo. O código foi desenvolvido utilizando a linguagem <em>Python</em>.</p>
</div>
<div class="listingblock data-line-0">
<div class="title">Código completo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  equalize.py
# Autor: Igor Barbosa
# Última atualização : 25/10/2022
import cv2 as cv
import numpy as np

webcam = cv.VideoCapture(0)


if webcam.isOpened():
    validacao, frame = webcam.read()

    while validacao:
        validacao, frame = webcam.read()
        framegray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        histEqualize = cv.equalizeHist(framegray) #imagem Equalizada
        
        #Geração dos histogramas
        histSize = 64
        hist = cv.calcHist(framegray, [0], None, [histSize], (0,255), False)
        histEqual = cv.calcHist(histEqualize, [0], None, [histSize], (0,255), False)

        #Tamanho dos histogramas
        hist_w = 200
        hist_h = 100
        bin_w = int(round(hist_w/histSize))

        #Matrizes dos histogramas
        histImage = np.zeros((hist_h, hist_w), dtype=np.uint8)
        histImageEqual = np.zeros((hist_h, hist_w), dtype=np.uint8)

        #Normalização dos histogramas
        cv.normalize(hist, hist, 0, hist_h, norm_type=cv.NORM_MINMAX)
        cv.normalize(histEqual, histEqual, 0, hist_h, norm_type=cv.NORM_MINMAX)

        for i in range(1, histSize):
            cv.line(histImage, (bin_w*(i), hist_h - int(hist[i])),
                               (bin_w*(i), hist_h),
                               (255, 255, 255), thickness=2)
            cv.line(histImageEqual, (bin_w*(i), hist_h - int(histEqual[i])),
                               (bin_w*(i), hist_h),
                               (255, 255, 255), thickness=2)

        for x in range (0, hist_h-1):
            for y in range (0, hist_w-1):
                framegray[x,y] = histImage[x,y]
                histEqualize[x,y] = histImageEqual[x,y]

        cv.imshow('Hist', framegray)
        cv.imshow('Equalize',histEqualize)
        key = cv.waitKey(5)
        if key == 27: #esc
            break

cv.imwrite('./4.Equalize/Entrada.png', framegray)
cv.imwrite('./4.Equalize/EntradaEqualizada.png', histEqualize)
webcam.release()
cv.destroyAllWindows</code></pre>
</div>
</div>
<div class="paragraph data-line-366">
<p>Neste exercícios iremos utilizar as bibliotecas do OpenCV e NumPy. O código começa com a chamada para utilização da <em>webcam</em> através de <em>cv.VideoCapture(0)</em>. Se estiver tudo certo com a captura da imagem, o programa entra em um <em>loop</em> orientado pela variável <strong>validacao</strong>, que está ligado com o <em>status</em> de conexão da <em>webcam</em>, ou seja, enquanto o dispositivo de captura estiver conectado, o código permanecerá executando o <em>loop</em>.</p>
</div>
<div class="paragraph data-line-368">
<p>O método <em>webcam.read()</em> fornece o <em>status</em> de conexão do dispositivo de captura e o frame do momento de execução.</p>
</div>
<div class="paragraph data-line-370">
<p>Logo após, temos o <em>frame</em> capturado transformado para a escala cinza e armazenado em <strong>framegray</strong>. Utilizando a função <em>cv.equalizeHist</em>, equalizamos o frame capturado e armazenamos em <strong>histEqualize</strong>.</p>
</div>
<div class="listingblock data-line-374">
<div class="title">Bibliotecas, captura de vídeo e transformação dos frames</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2 as cv
import numpy as np

webcam = cv.VideoCapture(0)


if webcam.isOpened():
    validacao, frame = webcam.read()

    while validacao:
        validacao, frame = webcam.read()
        framegray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)
        histEqualize = cv.equalizeHist(framegray) #imagem Equalizada</code></pre>
</div>
</div>
<div class="paragraph data-line-390">
<p>Através do método <em>cv.calcHist</em> é gerado o histograma de cada imagem.</p>
</div>
<div class="listingblock data-line-394">
<div class="title">Geração e definição do tamanho dos histogramas</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">        #Geração dos histogramas
        histSize = 64
        hist = cv.calcHist(framegray, [0], None, [histSize], (0,255), False)
        histEqual = cv.calcHist(histEqualize, [0], None, [histSize], (0,255), False)

        #Tamanho dos histogramas
        hist_w = 200
        hist_h = 100
        bin_w = int(round(hist_w/histSize))</code></pre>
</div>
</div>
<div class="paragraph data-line-406">
<p>Para a manipulação das imagens dos histogramas utilizamos a biblioteca <em>NumPy</em>. Para normalização dos histogramas utilizamos o método <em>cv.normalize</em> do próprio OpenCV.</p>
</div>
<div class="listingblock data-line-410">
<div class="title">Geração das matrizes dos histogramas e normalização dos mesmos</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">        #Matrizes dos histogramas
        histImage = np.zeros((hist_h, hist_w), dtype=np.uint8)
        histImageEqual = np.zeros((hist_h, hist_w), dtype=np.uint8)

        #Normalização dos histogramas
        cv.normalize(hist, hist, 0, hist_h, norm_type=cv.NORM_MINMAX)
        cv.normalize(histEqual, histEqual, 0, hist_h, norm_type=cv.NORM_MINMAX)</code></pre>
</div>
</div>
<div class="paragraph data-line-420">
<p>Finalmente, com todos os dados obtidos e tratados, poderemos gerar as representações dos histogramas. Para tal, utilizamos o método <em>cv.line</em>.</p>
</div>
<div class="listingblock data-line-424">
<div class="title">Histogramas transformados em imagens</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">        for i in range(1, histSize):
            cv.line(histImage, (bin_w*(i), hist_h - int(hist[i])),
                               (bin_w*(i), hist_h),
                               (255, 255, 255), thickness=2)
            cv.line(histImageEqual, (bin_w*(i), hist_h - int(histEqual[i])),
                               (bin_w*(i), hist_h),
                               (255, 255, 255), thickness=2)</code></pre>
</div>
</div>
<div class="paragraph data-line-434">
<p>Tendo como resultado final:</p>
</div>
<div class="imageblock data-line-437">
<div class="content">
<img src="./4.equalize/Entrada.png" alt="Entrada">
</div>
<div class="title">Figure 10. Frame capturado junto ao seu histograma.</div>
</div>
<div class="imageblock data-line-440">
<div class="content">
<img src="./4.equalize/EntradaEqualizada.png" alt="EntradaEqualizada">
</div>
<div class="title">Figure 11. Frame capturado e equalizado junto ao seu histograma.</div>
</div>
</div>
</div>
<div class="sect1 data-line-444">
<h2 id="_5_motiondetector">5. Motiondetector</h2>
<div class="sectionbody">
<div class="paragraph data-line-445">
<p>Neste quinto exercício pedia-se:</p>
</div>
<div class="exampleblock data-line-446">
<div class="content">
<div class="paragraph data-line-447">
<p>Utilizando o programa <em>exemplos/histogram.cpp</em> como referência, implemente um programa <strong>motiondetector.cpp</strong>. Este deverá continuamente calcular o histograma da imagem (apenas uma componente de cor é suficiente) e compará-lo com o último histograma calculado. Quando a diferença entre estes ultrapassar um limiar pré-estabelecido, ative um alarme. Utilize uma função de comparação que julgar conveniente.</p>
</div>
</div>
</div>
<div class="paragraph data-line-450">
<p>A solução da problemática está demonstrada abaixo. O código foi desenvolvido utilizando a linguagem <em>Python</em>.</p>
</div>
<div class="listingblock data-line-0">
<div class="title">Código completo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  motiondetector.py
# Autor: Igor Barbosa
# Última atualização : 25/10/2022
import cv2 as cv
import numpy as np
import imageio

gif = []

webcam = cv.VideoCapture(0)

#teste com a câmera
if webcam.isOpened():
    validacao, frame = webcam.read()

    while validacao:
        validacao, quadro1 = webcam.read() #frame anterior
        frame1 = cv.cvtColor(quadro1, cv.COLOR_BGR2GRAY)
        cv.waitKey(25)
        quadro2 = webcam.read()[1]         #frame atual
        frame2 = cv.cvtColor(quadro2, cv.COLOR_BGR2GRAY)
        
        #Geração dos histogramas
        histSize = 64
        histframe1 = cv.calcHist(frame1, [0], None, [histSize], (0,255), False)
        histframe2 = cv.calcHist(frame2, [0], None, [histSize], (0,255), False)

        #Comparação dos histogramas
        limiar = cv.compareHist(histframe1, histframe2, cv.HISTCMP_CORREL)
        if limiar &lt; 0.94 : #limiar definido para detecção de movimento
            cv.putText(frame2, 'Motion Detected!', (300,400), cv.FONT_ITALIC, 1, (0,0,0), thickness=2)

        #Exibição do frame atual capturado com suas respectivas informações
        hist_w = 200
        hist_h = 100
        bin_w = int(round(hist_w/histSize))
        histImage = np.zeros((hist_h, hist_w), dtype=np.uint8)
        cv.normalize(histImage, histImage, 0, hist_h, norm_type=cv.NORM_MINMAX)
        for i in range(1, histSize):
            cv.line(histImage, (bin_w*(i), hist_h - int(histframe1[i])),
                               (bin_w*(i), hist_h),
                               (255, 255, 255), thickness=2)

        for x in range (0, hist_h-1):
            for y in range (0, hist_w-1):
                frame2[x,y] = histImage[x,y]
        
        #cv.imshow('Webcam1', frame1)
        cv.imshow('Webcam', frame2)
        key = cv.waitKey(5)
        if key == 27: #esc
            break

        #Ao apertar a tecla "a", o programa irá armazenar os frames para gerar um gif
        if key == ord("a"):
            gif.append(frame2)
        
webcam.release()
cv.destroyAllWindows
#geração do gif através da biblioteca imageio
print("Saving GIF file")
with imageio.get_writer("./5.motiondetector/resultado.gif", mode="I") as writer:
    for idx, frame in enumerate(gif):
        print("Adding frame to GIF file: ", idx + 1)
        writer.append_data(frame)</code></pre>
</div>
</div>
<div class="paragraph data-line-458">
<p>Muitas funcionalidades são idênticas ao exercício anterior, por isso, vamos focar apenas no que foi feito para a problemática em questão.</p>
</div>
<div class="paragraph data-line-460">
<p>Primeiramente, dentro do <em>while</em> de captura de imagem da <em>webcam</em>, pegamos dois frames, separados pelo tempo presente no método <em>cv.waitKey()</em>. Depois, geramos os histogramas dos respectivos <em>frames</em> e comparamos através do método <em>cv.compareHist</em>. Caso a comparação forneça um valor abaixo de <strong>limiar=0.94</strong>, emitimos um alerta de _"Motion Detected".</p>
</div>
<div class="listingblock data-line-464">
<div class="title">Detecção de movimento</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">        frame1 = cv.cvtColor(quadro1, cv.COLOR_BGR2GRAY)
        cv.waitKey(25)
        quadro2 = webcam.read()[1]         #frame atual
        frame2 = cv.cvtColor(quadro2, cv.COLOR_BGR2GRAY)

        #Geração dos histogramas
        histSize = 64
        histframe1 = cv.calcHist(frame1, [0], None, [histSize], (0,255), False)
        histframe2 = cv.calcHist(frame2, [0], None, [histSize], (0,255), False)

        #Comparação dos histogramas
        limiar = cv.compareHist(histframe1, histframe2, cv.HISTCMP_CORREL)
        if limiar &lt; 0.94 : #limiar definido para detecção de movimento
            cv.putText(frame2, 'Motion Detected!', (300,400), cv.FONT_ITALIC, 1, (0,0,0), thickness=2)</code></pre>
</div>
</div>
<div class="paragraph data-line-481">
<p>Para a demonstração do funcionamento do algoritmo, utilizamos a biblioteca <strong>imageio</strong>, na qual, ao clicarmos em uma tecla, armazena-se <em>frames</em> e depois cria-se um arquivo <em>.gif</em>.</p>
</div>
<div class="listingblock data-line-485">
<div class="title">Parte do código destinada a gravação de um arquivo .gif.</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import imageio

gif = []

 #Ao apertar a tecla "a", o programa irá armazenar os frames para gerar um gif
        if key == ord("a"):
            gif.append(frame2)

#geração do gif através da biblioteca imageio
print("Saving GIF file")
with imageio.get_writer("./5.motiondetector/resultado.gif", mode="I") as writer:
    for idx, frame in enumerate(gif):
        print("Adding frame to GIF file: ", idx + 1)
        writer.append_data(frame)</code></pre>
</div>
</div>
<div class="paragraph data-line-502">
<p>Tendo como saída:</p>
</div>
<div class="imageblock data-line-505">
<div class="content">
<img src="./5.motiondetector/resultado.gif" alt="resultado">
</div>
<div class="title">Figure 12. Saída do programa motiondetector.py.</div>
</div>
<div class="sect2 data-line-507">
<h3 id="_5_1_aidentudetector">5.1. Aidentudetector</h3>
<div class="exampleblock data-line-509">
<div class="content">
<div class="paragraph data-line-510">
<p><em>Eis que um Cearense começa a aprender PDI&#8230;&#8203;</em></p>
</div>
</div>
</div>
<div class="imageblock data-line-514">
<div class="content">
<img src="./imagens/aidentu.gif" alt="aidentu">
</div>
<div class="title">Figure 13. Aidentudetector em pleno funcionamento.</div>
</div>
<div class="imageblock data-line-517">
<div class="content">
<img src="./imagens/HumorLaplaciano.png" alt="HumorLaplaciano">
</div>
<div class="title">Figure 14. Humor laplaciano.</div>
</div>
</div>
</div>
</div>
<div class="sect1 data-line-520">
<h2 id="_6_laplgauss">6. Laplgauss</h2>
<div class="sectionbody">
<div class="paragraph data-line-521">
<p>Neste sexto exercício pedia-se:</p>
</div>
<div class="exampleblock data-line-522">
<div class="content">
<div class="paragraph data-line-523">
<p>Utilizando o programa <em>exemplos/filtroespacial.cpp</em> como referência, implemente um programa <strong>laplgauss.cpp</strong>. O programa deverá acrescentar mais uma funcionalidade ao exemplo fornecido, permitindo que seja calculado o laplaciano do gaussiano das imagens capturadas. Compare o resultado desse filtro com a simples aplicação do filtro laplaciano.</p>
</div>
</div>
</div>
<div class="paragraph data-line-526">
<p>A solução da problemática está demonstrada abaixo. O código foi desenvolvido utilizando a linguagem <em>Python</em>.</p>
</div>
<div class="listingblock data-line-0">
<div class="title">Código completo</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python"># Nome:  laplgauss.py
# Autor: Igor Barbosa
# Última atualização : 24/10/2022
import cv2 as cv
import numpy as np

#máscaras dos filtros
gauss = np.array([[0.0625, 0.125, 0.0625]   #borramento
                ,[0.125, 0.25, 0.125]
                ,[0.0625, 0.125, 0.0625]])

laplacian = np.array([[0, -1, 0]
                     ,[-1, 4, -1]
                     ,[0, -1, 0]])


webcam = cv.VideoCapture(0)

if webcam.isOpened():
    validacao, frame = webcam.read()

    while validacao:
        validacao, frame = webcam.read()
        framegray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) #aquisição original
        cv.imshow("Aquisicao", framegray)

        framegaussiano = cv.filter2D(framegray, -1, gauss)
        cv.imshow('Borramento', framegaussiano)

        framelaplaciano = cv.filter2D(framegray, -1, laplacian)
        cv.imshow('Laplaciano', framelaplaciano)

        framelaplgauss = cv.filter2D(framegaussiano, -1, laplacian)
        cv.imshow('LaplGauss', framelaplgauss)

        key = cv.waitKey(5)
        if key == 27: #esc
            break
    cv.imwrite('./6.laplgauss/GrayFrame.png', framegray)
    cv.imwrite('./6.laplgauss/FrameGaussiano.png', framegaussiano)
    cv.imwrite('./6.laplgauss/FrameLaplaciano.png', framelaplaciano)
    cv.imwrite('./6.laplgauss/FrameLaplGauss.png', framelaplgauss)


webcam.release()
cv.destroyAllWindows</code></pre>
</div>
</div>
<div class="paragraph data-line-534">
<p>Neste exercício, utilizamos as bibliotecas do OpenCV e NumPy. O NumPy será usado com as máscaras, que nesse caso serão duas: uma máscara de gauss, que permite o borramento, e uma máscara de laplaciano, que permite a obtenção das bordas.</p>
</div>
<div class="listingblock data-line-538">
<div class="title">Bibliotecas e máscaras</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">import cv2 as cv
import numpy as np

#máscaras dos filtros
gauss = np.array([[0.0625, 0.125, 0.0625]   #borramento
                ,[0.125, 0.25, 0.125]
                ,[0.0625, 0.125, 0.0625]])

laplacian = np.array([[0, -1, 0]
                     ,[-1, 4, -1]
                     ,[0, -1, 0]])</code></pre>
</div>
</div>
<div class="paragraph data-line-551">
<p>Depois, teremos o trabalho com a câmera e os tratamentos dos frames capturados utilizando o método <em>cv.cvtColor</em>, para transformar o frame colorido para escala cinza, e <em>cv.filter2D</em> para aplicação das máscaras.</p>
</div>
<div class="listingblock data-line-555">
<div class="title">Câmera e tratamento dos frames</div>
<div class="content">
<pre class="highlightjs highlight"><code class="language-python hljs" data-lang="python">webcam = cv.VideoCapture(0)

if webcam.isOpened():
    validacao, frame = webcam.read()

    while validacao:
        validacao, frame = webcam.read()
        framegray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY) #aquisição original
        cv.imshow("Aquisicao", framegray)

        framegaussiano = cv.filter2D(framegray, -1, gauss)
        cv.imshow('Borramento', framegaussiano)

        framelaplaciano = cv.filter2D(framegray, -1, laplacian)
        cv.imshow('Laplaciano', framelaplaciano)

        framelaplgauss = cv.filter2D(framegaussiano, -1, laplacian)
        cv.imshow('LaplGauss', framelaplgauss)</code></pre>
</div>
</div>
<div class="paragraph data-line-576">
<p>Como saída temos:</p>
</div>
<div class="imageblock data-line-579">
<div class="content">
<img src="./6.laplgauss/GrayFrame.png" alt="GrayFrame">
</div>
<div class="title">Figure 15. Frame transformado para escala de cinza.</div>
</div>
<div class="imageblock data-line-582">
<div class="content">
<img src="./6.laplgauss/FrameGaussiano.png" alt="FrameGaussiano">
</div>
<div class="title">Figure 16. Frame com borramento (máscara gaussiana).</div>
</div>
<div class="imageblock data-line-585">
<div class="content">
<img src="./6.laplgauss/FrameLaplaciano.png" alt="FrameLaplaciano">
</div>
<div class="title">Figure 17. Frame com Laplaciano.</div>
</div>
<div class="imageblock data-line-588">
<div class="content">
<img src="./6.laplgauss/FrameLaplGauss.png" alt="FrameLaplGauss">
</div>
<div class="title">Figure 18. Frame com Laplaciano após o borramento.</div>
</div>
<div class="paragraph data-line-590">
<p>A máscara de Gauss é aplicada com o intuito de diminuir o ruído e realçar as bordas. Quando aplicamos o filtro laplaciano na imagem pura, temos o aspecto das bordas mais nítidas, porém, com uma relevante presença de ruído.</p>
</div>
<div class="paragraph data-line-592">
<p>Ao aplicarmos o filtro de gauss e depois o laplaciano, obtemos as bordas de maneira mais suave, porém, nitidamente mais puras e limpas, sem aspecto ruidoso.</p>
</div>
</div>
</div>
</div>
<div id="footer">
<div id="footer-text">
Last updated 2022-10-26 20:48:48 -0300
</div>
</div>
<script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.18.3/highlight.min.js"></script>
<script>
if (!hljs.initHighlighting.called) {
  hljs.initHighlighting.called = true
  ;[].slice.call(document.querySelectorAll('pre.highlight > code')).forEach(function (el) { hljs.highlightBlock(el) })
}
</script>
</body>
</html>